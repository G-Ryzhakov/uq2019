{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Galerkin Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "Consider the following PDE\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "u_t(x,\\,t,\\,\\xi)&=\\mathcal L(u), \\,\\, &D\\times(0,\\,T]\\times\\mathbb R^d,\\\\\n",
    "\\mathcal B(u)&=0,  &\\partial D\\times(0,\\,T]\\times\\mathbb R^d,\\\\\n",
    "u\\mid_{t=0}&=u_0, &D\\times\\mathbb R^d,\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "where $D\\subset\\mathbb R^l$ is physical domain of the process,\n",
    "$\\mathcal L$ is differential operator,\n",
    "$\\mathcal B$ is the boundary condition operator,\n",
    "$u_0$ is the initial condition,\n",
    "$\\xi$ is a random variable.\n",
    "\n",
    "Let's consider the gPC projection $u_N$ of the solution\n",
    "$$\n",
    "u_N(x,\\,t,\\,\\xi)=\\sum_{i=0}^N\\hat u_i(x,\\,t)p_i(\\xi),\\qquad\n",
    "\\hat u_i(x,\\,t)=\\frac1{\\gamma_i}\\mathbb E[u(x,\\,t,\\,\\xi)p_i(\\xi)]\n",
    "$$\n",
    "\n",
    "We assume that this projection approximates the solution to PDE quite well when $N$ is not very large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We immediately seek a solution in the form\n",
    "$$\n",
    "v_N(x,\\,t,\\,\\xi)=\\sum_{i=0}^N\\hat v_i(x,\\,t)p_i(\\xi)\n",
    "$$\n",
    "as in the classical Galerkin approach for deterministic equations.\n",
    "\n",
    "So, we get the following system for $i=0,\\,1,\\,\\ldots,\\,N$\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "\\mathbb E[\\partial_tv_N(x,\\,t,\\,\\xi)p_i(\\xi)]&=\\mathbb E[\\mathcal L(u)p_i(\\xi)], \\,\\, &D\\times(0,\\,T]\\times\\mathbb R^d,\\\\\n",
    "\\mathbb E[\\mathcal B(v_N)p_i(\\xi)]&=0,  &\\partial D\\times(0,\\,T]\\times\\mathbb R^d,\\\\\n",
    "\\hat v_i\\mid_{t=0}&=\\frac1{\\gamma_i}\\mathbb E[u_0p_i(\\xi)], &D\\times\\mathbb R^d,\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "In the multivariate case, \n",
    "the size  of the system will be $\\dim\\mathcal P_N={N+d\\choose N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ODE\n",
    "\n",
    "We will solve a very simple ODE to illustrate the method\n",
    "$$\n",
    "\\frac{du(t,\\,\\xi)}{dt}=-\\alpha(\\xi)u(t,\\,\\xi),\\qquad\n",
    "u(0,\\,\\xi)=\\beta,\n",
    "$$\n",
    "where $\\beta$ is deterministic.\n",
    "\n",
    "We assume that $\\alpha$ has a normal distribution $\\alpha\\sim\\mathcal N(\\mu,\\,\\sigma^2)$.\n",
    "\n",
    "So, we will use one-dimensional Hermite polynomials $\\{H_k(\\xi)\\}$ as a basis with $\\xi\\sim\\mathcal N(0,1)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The ODE parameter $\\alpha$ is a linear function $\\alpha=\\mu+\\sigma\\xi.$ Hence, we can have a projection of $\\alpha$ \n",
    "$$\n",
    "\\alpha_N(\\xi)=\\sum_{i=0}^Na_iH_i(\\xi),\n",
    "$$\n",
    "with \n",
    "$$\n",
    "a_0=\\mu,\\quad a_1=\\sigma,\\quad a_i=0,\\,\\,i>1.\n",
    "$$\n",
    "\n",
    "In this particular case, we have an exact relation\n",
    "$$\n",
    "\\alpha(\\xi)=\\alpha_N(\\xi),\\quad N>1.\n",
    "$$\n",
    "\n",
    "In the similar fashion, we obtain a projection for $\\beta$\n",
    "$$\n",
    "\\beta_N(\\xi)=\\sum_{i=0}^Nb_iH_i(\\xi),\n",
    "$$\n",
    "with \n",
    "$$\n",
    "b_0=\\beta,\\quad b_i=0,\\,\\,i>1.\n",
    "$$\n",
    "\n",
    "(we will not use the fact of truncating the series until the end of the solution, to show the general principle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We seek a solution in the form of gPC N-degree approximation\n",
    "$$\n",
    "v_N(t,\\,\\xi)=\\sum_{i=0}^N\\hat v_i(t)H_i(\\xi),\n",
    "$$\n",
    "and after substitution the expansions in\n",
    "$$\n",
    "\\mathbb E\\left[\\frac{dv_N}{dt}H_k\\right]=\n",
    "\\mathbb E[-\\alpha_Nv_NH_k],\n",
    "$$\n",
    "we got equations on unknown coefficients $\\hat v_k$\n",
    "$$\n",
    "\\frac{d\\hat v_k}{dt}=-\n",
    "\\frac1{\\gamma_k}\\sum_{i=0}^N\\sum_{j=0}^N\n",
    "\\alpha_i\\hat v_ie_{ijk},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "e_{ijk}=\n",
    "\\mathbb E[H_i(\\xi)H_j(\\xi)H_k(\\xi)].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The constants $e_{ijk}$ can be ''easily'' calculated\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "e_{ijk}&=\\frac{i!\\,j!\\,k!}{(s-i)!\\,(s-j)!\\,(s-k)!},\n",
    "\\;\n",
    "&&s=\\frac{i+j+k}2\\in\\mathcal N, \\,s\\geq i,j,k\\\\\n",
    "e_{ijk}&=0, &&\\text{otherwise}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "Recall that for Hermite polynomials $\\gamma_k=k!$.\n",
    "\n",
    "Thus, we have a deterministic system of ODE on $\\vec v=\\{\\hat v_i\\}$ which can  be written in a vector form\n",
    "$$\n",
    "\\frac{\\vec v_k(t)}{dt}=A \\vec v,\n",
    "$$\n",
    "with initial condition\n",
    "$$\n",
    "\\vec v(0)=\\vec b,\\quad \\vec b=\\{b_i\\},\n",
    "$$\n",
    "and system $(N+1)\\times(N+1)$ matrix $A=\\{A_{kj}\\}_0^N$ with elements\n",
    "$$\n",
    "A_{kj}=-\\frac1{\\gamma_k}\\sum_{i=0}^Na_ie_{ijk}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In our simple case, \n",
    "$$\n",
    "A_{kj}=-\\frac1{\\gamma_k}(\\mu e_{0jk}+\\sigma e_{1jk}),\n",
    "$$\n",
    "so, $A$ is tridiagonal,\n",
    "$$\n",
    "A_{j,j}=-\\mu,\n",
    "$$\n",
    "$$\n",
    "A_{j+1,j}=-\\sigma,\n",
    "$$\n",
    "$$\n",
    "A_{j,j+1}=-(j+1)\\sigma.\n",
    "$$\n",
    "\n",
    "We can calculate the gPC projection coefficients of the solution for different $N$\n",
    "$$\n",
    "\\vec v=e^{At}\\vec b.\n",
    "$$\n",
    "\n",
    "Also, we can find the exact solution to this problem\n",
    "$$\n",
    "u=\\beta e^{-\\alpha t}=\\beta e^{-\\mu t}e^{-\\sigma\\xi t}.\n",
    "$$\n",
    "\n",
    "The gPC projection \n",
    "coefficients of this kind of expression we know from [Lecture 4](lecture-4.ipynb)\n",
    "$$\n",
    "\\text{Pr}_Nu(t=1,\\,\\xi)=\n",
    "\\beta e^{-\\mu+\\sigma^2/2}\\sum_{k=0}^N\\frac{(-\\sigma)^k}{k!}H_k(\\xi).\n",
    "$$\n",
    "\n",
    "So, we can compare Stochastic Galerkin Method solution with the exact one choosing the different sets of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.sparse.linalg as SLA\n",
    "import scipy.sparse as SP\n",
    "\n",
    "\n",
    "def calc_A(N, mu=1, sigma=2):\n",
    "    data = np.empty((3, N))\n",
    "    data[0, ...] = mu\n",
    "    data[1, ...] = sigma\n",
    "    data[2, ...] = sigma*np.arange(N)\n",
    "    return SP.dia_matrix((-data, [0, -1, 1]), shape=(N, N)).tocsc()\n",
    "\n",
    "\n",
    "def calc_v_0(N, b0=1.0):\n",
    "    return SP.dia_matrix(([b0], 0), shape=(N, 1)).tocsc()\n",
    "\n",
    "\n",
    "def solution_coeffs(A, v_0, t):\n",
    "    return SLA.expm(A*t).dot(v_0).toarray().flatten()\n",
    "\n",
    "\n",
    "def solution(A, v_0, xi, T=1, num_t=100):\n",
    "    t = np.linspace(0, T, num_t)\n",
    "    sol = np.empty(num_t)\n",
    "    N = A.shape[0]\n",
    "    H_k = np.empty(N)\n",
    "    for i in range(N):\n",
    "        H_k[i] = p_herm(i, xi)\n",
    "\n",
    "    for i, ti in enumerate(t):\n",
    "        sol[i] = SLA.expm(A*ti).dot(v_0).toarray().flatten().dot(H_k)\n",
    "\n",
    "    return sol\n",
    "\n",
    "\n",
    "def exact_solution(N, mu, sigma):\n",
    "    sol = np.empty(N)\n",
    "    sol[0] = 1.0\n",
    "    for i in range(1, N):\n",
    "        sol[i] = sol[i-1]*(-sigma)/i\n",
    "    return sol*np.exp(-mu + sigma*sigma/2.0)\n",
    "\n",
    "\n",
    "def plot_both_solutions(N, mu, sigma):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(exact_solution(N, mu, sigma), label='exact')\n",
    "\n",
    "    A = calc_A(N, mu, sigma)\n",
    "    v_0 = calc_v_0(N)\n",
    "    cf = solution_coeffs(A, v_0, 1.0)\n",
    "    plt.plot(cf, label='SGm')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "from ipywidgets import interact, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28843115817449390c7f78b0055f510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='# of terms (N)', max=25, min=1), FloatSlider(value=0.0, description='$\\\\mu$', max=5.0, min=-5.0, step=0.25), FloatSlider(value=2.0, description='$\\\\sigma$', max=5.0, step=0.25), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_both_solutions,  \n",
    "         N=widgets.IntSlider(min=1,max=25,step=1,value=5,continuous_update=True,description='# of terms (N)'),\n",
    "         mu=widgets.FloatSlider(min=-5,max=5,step=.25,value=0,continuous_update=True,description=r'$\\mu$'),\n",
    "         sigma=widgets.FloatSlider(min=0,max=5,step=.25,value=2,continuous_update=True,description=r'$\\sigma$')\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperbolic Equations\n",
    "\n",
    "Consider a simple wave equation\n",
    "$$\n",
    "\\frac{\\partial u(x,t,\\xi)}{\\partial t}=c(\\xi)\n",
    "\\frac{\\partial u(x,t,\\xi)}{\\partial x},\\qquad\n",
    "x\\in(-1,\\,1),\\;\\;t>0,\n",
    "$$\n",
    "where $c(\\xi)$ is a random transport velocity.\n",
    "The initial condition is\n",
    "$$\n",
    "u(x,0,\\xi)=u_0(x,\\xi).\n",
    "$$\n",
    "\n",
    "The boundary conditions depend on the sign of $c$\n",
    "(this sign determines in which direction the wave propagates)\n",
    "$$\n",
    "\\begin{align}\n",
    "u(1,t,\\xi)&=u_R(t,\\xi),& c(\\xi)&>0,\n",
    "\\\\\n",
    "u(-1,t,\\xi)&=u_L(t,\\xi),& c(\\xi)&<0.\n",
    "\\end{align}\n",
    "$$\n",
    "In this behavior, the stochastic equation differs significantly from the classical one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us use normalized polynomials\n",
    "$$\n",
    "\\mathbb E[p_i(\\xi)p_j(\\xi)]=\\delta_{ij},\n",
    "$$\n",
    "and we haven't specify them yet. \n",
    "\n",
    "We seek the solution in the form of gPC expansion\n",
    "$$\n",
    "v_N(x,t,\\xi)=\\sum_{i=0}^N\\hat v_N(x,t)p_i(\\xi),\n",
    "$$\n",
    "and projecting the equation\n",
    "$$\n",
    "\\mathbb E\\left[\n",
    "\\frac{\\partial u(x,t,\\xi)}{\\partial t}p_k(\\xi)\\right]=\n",
    "\\mathbb E\\left[c(\\xi)\n",
    "\\frac{\\partial u(x,t,\\xi)}{\\partial x}p_k(\\xi)\\right],\n",
    "$$\n",
    "on the $k^\\text{th}$ element of gPC basis, we obtain\n",
    "$$\n",
    "\\frac{\\partial\\hat v_k(x,t)}{\\partial t}=\n",
    "\\sum_{i=0}^Na_{ki}\n",
    "\\frac{\\partial\\hat v_i(x,t)}{\\partial x},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "a_{ki}=\\mathbb E[c(\\xi)p_k(\\xi)p_i(\\xi)].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Again, we got a system of deterministic equations with the matrix $A=a_{ik}$, \n",
    "$$\n",
    "\\frac{\\partial\\vec v(x,t)}{\\partial t}=\n",
    "A\n",
    "\\frac{\\partial\\vec v(x,t)}{\\partial x}.\n",
    "$$\n",
    "Note that now the system matrix is symmetric, $A^T=A$, so a complete set of real eigenvalues and eigenfunctions exists.\n",
    "There exists an orthogonal matrix $S^T=S^{-1}$\n",
    "such that $\\Lambda=S^TAS$ is diagonal\n",
    "$$\n",
    "\\Lambda=\\mathop{\\text{diag}}\n",
    "(\\underbrace{\\lambda_0,\\,\\dots,\\,\\lambda_{j_+}}_{>0},\n",
    "0,\\,\\ldots,0,\\,\n",
    "\\underbrace{\\lambda_{j_-},\\ldots,\\,\\lambda_N}_{<0}).\n",
    "$$\n",
    "\n",
    "The sign of the eigenvalue is very important, since it determines which of the boundary conditions we will use (see the\n",
    "[paper](https://utah.pure.elsevier.com/en/publications/galerkin-method-for-wave-equations-with-uncertain-coefficients) for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Denote $\\vec q=\\{q_0,\\,q_1,\\,\\ldots,\\,q_N\\}^T=S^T\\vec v $ and we obtain independent equations on $\\vec q$ \n",
    "$$\n",
    "\\frac{\\partial\\vec q(x,t)}{\\partial t}=\n",
    "\\Lambda\n",
    "\\frac{\\partial\\vec q(x,t)}{\\partial x}.\n",
    "$$\n",
    "Boundary conditions depend on sign of eigenvalues\n",
    "$$\n",
    "\\begin{align}\n",
    "q_j(1,t)&=\\sum_{k=0}^Ns_{kj}\\hat u_k(1,t),&\n",
    "j&=0,\\,\\dots,\\,j_+,& (\\lambda_j&>0),\n",
    "\\\\\n",
    "q_j(-1,t)&=\\sum_{k=0}^Ns_{kj}\\hat u_k(-1,t),&\n",
    "j&=j_-,\\ldots,\\,N,& (\\lambda_j&<0).\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Error bound\n",
    "\n",
    "The solution to the gPC Galerkin system converges to the exact solution. In fact, the following error bound was estimated (see the\n",
    "[paper](https://utah.pure.elsevier.com/en/publications/galerkin-method-for-wave-equations-with-uncertain-coefficients))\n",
    "$$\n",
    "\\mathbb E\\left[\\|u-v_N\\|_{L_2}^2\\right]\\leq\\frac C{N^{2m-1}}t,\n",
    "$$\n",
    "where $m>0$ depends on the smoothness of $u$ in terms of $\\xi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diffusion Equations\n",
    "\n",
    "Let us consider a time-dependent stochastic diffusion equation\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "\\frac{\\partial u(x,t,\\xi)}{\\partial t}\n",
    "=\n",
    "\\mathop{\\text{div}}\n",
    "\\bigl(k(x,\\xi)\\mathop{\\text{grad}}(u)\\bigr)\n",
    "+f(t,x),\\qquad x\\in D,\\\\\n",
    "u(x,0,\\xi)=u_0(x),\\qquad u\\mid_{\\partial D}=0,\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "We assume that $k$ has the form\n",
    "$$\n",
    "k(x,\\xi)=\\hat k_0(x)+\\sum_{i=1}^d\\hat k_i(x)\\xi_i,\n",
    "$$\n",
    "where $\\xi=(\\xi_1,\\,\\xi_2,\\,\\ldots,\\,\\xi_d)$ are i.i.d. r.v.\n",
    "Some ways of representing a random field as a finite combination of random variables will be considered in the following lectures.\n",
    "\n",
    "For the problem to be well posed, we require\n",
    "$$\n",
    "k(x,\\xi)\\geq k_{\\text{min}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As usual, we seek the solution in the form of\n",
    "$$\n",
    "v_N(t,x,\\xi)=\\sum_{|k|=0}^N\\hat v_k(t,x)p_k(\\xi),\n",
    "$$\n",
    "where $k$ is multi-index and we use normalized polynomials\n",
    "$$\n",
    "\\mathbb E[p_i(\\xi)p_j(\\xi)]=\\delta_{ij}.\n",
    "$$\n",
    "For the simplicity, we will use single-index $i$ instead of $k$\n",
    "$$\n",
    "v_N(t,x,\\xi)=\\sum_{i=1}^M\\hat v_i(t,x)p_i(\\xi),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "M={N+d\\choose N}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Substituting the gPC expansion of the solution form to the equation and projecting the resulting equation, we get\n",
    "$$\n",
    "\\frac{\\partial \\hat v_k(t,x)}{\\partial t}=\n",
    "\\sum_{i=0}^d\n",
    "\\sum_{j=1}^M\n",
    "\\mathop{\\text{div}}\n",
    "\\bigl(\\hat k_i(x)\\mathop{\\text{grad}}(\\hat v_j)\\bigr)e_{ijk}\n",
    "+\\hat f_k(t, x)=\n",
    "$$\n",
    "$$\n",
    "\\sum_{j=1}^M\n",
    "\\mathop{\\text{div}}\n",
    "\\bigl(a_{jk}(x)\\mathop{\\text{grad}}(\\hat v_j)\\bigr)\n",
    "+\\hat f_k(t, x),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "e_{ijk}=\n",
    "\\mathbb E[\\xi_ip_jp_k]=\n",
    "\\int z_ip_j(z)p_k(z)\\,dF_\\xi(z),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "a_{jk}(x)=\n",
    "\\sum_{i=0}^d\\hat k_i(x)e_{ijk}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The equation presented in the vector form \n",
    "$$\n",
    "\\frac{\\partial\\vec v(t,x)}{\\partial t}=\n",
    "\\mathop{\\text{div}}\n",
    "\\bigl(A(x)\\mathop{\\text{grad}}(\\hat v_j)\\bigr)\n",
    "+\\hat f,\n",
    "$$\n",
    "$$\n",
    "\\vec v(0,x)=\\vec v_0(x),\\quad \\vec v\\mid_{\\partial D},\n",
    "$$\n",
    "where $A(x)=\\{a_{ij}(x)\\}$ is symmetric,\n",
    "$\\vec v=\\{\\hat v_k(t,x)\\}$,\n",
    "$\\vec f=\\{\\hat f_k(t,x)\\}$.\n",
    "\n",
    "This deterministic system of equations is usually integrated numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Collocation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In deterministic numerical analysis, collocation methods require that the residue of the governing equations to be zero at discrete nodes in the computational domain.\n",
    "The nodes are called **collocation** points.\n",
    "We can extend this idea to the stochastic simulations.\n",
    "\n",
    "Consider a PDE\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "u_t(x,\\,t,\\,\\xi)&=\\mathcal L(u), \\,\\, &D\\times(0,\\,T]\\times I_\\xi,\\\\\n",
    "\\mathcal B(u)&=0,  &\\partial D\\times(0,\\,T]\\times I_\\xi,\\\\\n",
    "u\\mid_{t=0}&=u_0, &D\\times I_\\xi,\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "where $I_\\xi$ is the support of $\\xi$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $\\Theta_M=\\{\\xi^{(j)}\\}^M_{j=1}\\subset I_\\xi$\n",
    "be a set of nodes in the random space.\n",
    "Then in the collocation method, for all $j = 1,...,M$, we enforce the PDE at the node $\\xi^{(j)}$ by solving\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "u_t(x,\\,t,\\,\\xi^{(j)})&=\\mathcal L(u), \\,\\, &D\\times(0,\\,T],\\\\\n",
    "\\mathcal B(u)&=0,  &\\partial D\\times(0,\\,T],\\\\\n",
    "u\\mid_{t=0}&=u_0, &D.\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "For each $j$ it is a deterministic problem.\n",
    "Let $u^{(j)} = u(\\cdot,\\xi^{(j)})$ be the  set of solutions of the above problem. \n",
    "We can extract useful information about $u(\\xi)$ from this set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition (Stochastic collocation).** *Let  $\\Theta_M = \\{\\xi^{(j)}\\}^M_{j=1} ⊂ I_\\xi$ be a set of (prescribed) nodes in the random space, where $M ≥ 1$ is the number of nodes,\n",
    "and let $\\{u^{(j)}\\}^M_{j=1}$ be the solution of the governing equation.\n",
    "Then find $w(\\xi) ∈  \\mathcal P(\\xi)$ in a proper polynomial space  $\\mathcal P(\\xi)$\n",
    "such that $w(\\xi)$ is an approximation to the true solution $u(\\xi)$ in the sense that $\\|w(\\xi) - u(\\xi)\\|$ is sufficiently small in a strong norm defined on $I_\\xi$.*\n",
    "\n",
    "Typically, the $L_p$ norm is used.\n",
    "\n",
    "Convergence of stochastic collocation thus requires\n",
    "$$\n",
    "\\|w(\\xi) - u(\\xi)\\|\\to0,\\qquad M\\to\\infty.\n",
    "$$\n",
    "\n",
    "There exist two major approaches for high-order stochastic collocation: the *interpolation approach*\n",
    "and the *discrete projection approach* (the *pseudospectral approach*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpolation approach\n",
    "\n",
    "We have met this approach before -- find a polynomial $w$ form a given space $\\mathcal P$ of polynomials such that $w(\\xi^{(j)})=u^{(j)}$.\n",
    "\n",
    "One can use *Lagrange interpolation approach* for this\n",
    "$$\n",
    "w(\\xi)=\\sum_{j=1}^Mu(\\xi^{(j)})L_j(\\xi)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "L_j(\\xi^{(i)})=\\delta_{ij}.\n",
    "$$\n",
    "are the Lagrange interpolating polynomials.\n",
    "In the multivariate case the theory is not so clear as in 1D. \n",
    "For example, \n",
    "existence of Lagrange interpolating polynomials for any given set of notes are not well understood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The other way is a matrix inversion approach, where we prescribe the polynomial interpolating basis first. For example, let us use a set of gPC polynomial bases  $p_k(\\xi)$ and construct\n",
    "$$\n",
    "w_N(\\xi)=\\sum_{|k|=0}^N\\hat w_kp_k(\\xi).\n",
    "$$\n",
    "The interpolation condition $w(\\xi^{(j)})=u^{(j)}$\n",
    "results in the following problem\n",
    "for the unknown expansion coefficients\n",
    "$$\n",
    "A^T\\hat w=u,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "A=p_k(\\xi^{(j)})\n",
    "$$\n",
    "is the Vandermonde-like coefficient matrix,\n",
    "$\\hat w$ is the vector of the expansion coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Node selection\n",
    "\n",
    "A typical strategies for node selection are\n",
    "\n",
    "- Tensor product\n",
    "- Random of pseudo-random (with low-discrepancy) point set\n",
    "- Sparse grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete Projection: Pseudospectral Approach\n",
    "\n",
    "Recall, that in 1D the cubature rule, it is an integration rule that seeks to approximate an integral\n",
    "$$\n",
    "\\int f(z)\\,\\text{d}F_Z(z)\n",
    "$$\n",
    "by\n",
    "$$\n",
    "U^Q[f]:=\\sum_{j=1}^Qf(z^{(j)})\\alpha^{(j)},\n",
    "$$\n",
    "where $z^{(j)}$, $\\alpha^{(j)}$ are the nodes\n",
    "and their corresponding weights.\n",
    "The integration rule is convergent if it converges to the integral as $Q\\to\\infty$.\n",
    "\n",
    "An integration rule of degree $m$ implies that the approximation $U^Q$ is exact for any integrand $f$ that is a polynomial of degree up to $m$ and is not exact for at least one polynomial of degree $m + 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The coefficients $\\hat u_k$ of the\n",
    "orthogonal gPC projection of $u$\n",
    "$$\n",
    "u_N(\\xi)={\\text{Pr}}_Nu=\n",
    "\\sum_{|k|=0}^N\\hat u_kp_k(k)\n",
    "$$\n",
    "are expressed in terms of the corresponding integrals\n",
    "$$\n",
    "\\hat u_k=\n",
    "\\frac1{\\gamma_k}\n",
    "\\int u(z)p_k(z)\\,\\text{d}F_\\xi(z).\n",
    "$$\n",
    "\n",
    "The idea is to approximate\n",
    "the integrals in the expansion coefficients \n",
    "by an integration rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The discrete projection of the solution of the PDE, which we considered above, is\n",
    "$$\n",
    "w_N(\\xi)=\n",
    "\\sum_{|k|=0}^N\\hat w_kp_k(k)\n",
    "$$\n",
    "where the expansion coefficients are\n",
    "$$\n",
    "\\hat w_k=\\frac1{\\gamma_k}\n",
    "U^Q[u(\\xi)p_k(\\xi)]=\n",
    "\\frac1{\\gamma_k}\\sum_{j=1}^Qu(z^{(j)})p_k(z^{(j)})\\alpha^{(j)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition**\n",
    "*For $u(\\xi)\\in L^2_{dF_\\xi}(I_\\xi)$,\n",
    "let $u_N(\\xi)$ be the gPC projection of $u$ and let\n",
    "$w_N(\\xi)$ be the discrete gPC projection for $u$.\n",
    "Assume that the cubature rule $U^Q$ is convergent;\n",
    "then as $Q\\to\\infty$, $\\hat w_k\\to\\hat u_k$, for all $|k|\\leq N$, and\n",
    "$$\n",
    "w_N(\\xi)\\to u_N(\\xi),\\quad\\forall \\xi.\n",
    "$$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can estimate the error induced by $w_N$.\n",
    "\n",
    "**Proposition**\n",
    "*For $u(\\xi)\\in L^2_{dF_\\xi}(I_\\xi)$,\n",
    "let $u_N(\\xi)$ be the gPC projection of $u$ and let\n",
    "$w_N(\\xi)$ be the discrete gPC projection for $u$.\n",
    "Then,\n",
    "$$\n",
    "\\|w_N(\\xi)-u(\\xi)\\|_{L^2_{dF_\\xi}}\\leq\n",
    "\\|u_N(\\xi)-u(\\xi)\\|_{L^2_{dF_\\xi}}+\n",
    "\\|w_N(\\xi)-u_N(\\xi)\\|_{L^2_{dF_\\xi}}.\n",
    "$$*\n",
    "\n",
    "The first term of the error is the gPC projection error induced by using finite-order ($N^{\\text{th}}$-order) polynomials. The second term of the error is the difference between the continuous gPC projection and the discrete projection and is caused by using a cubature rule with finite accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can express the second error as\n",
    "$$\n",
    "\\epsilon^Q_N:=\n",
    "\\|w_N(\\xi)-u_N(\\xi)\\|_{L^2_{dF_\\xi}}\n",
    "$$\n",
    "$$=\n",
    "\\left(\\sum_{|k|=0}^N(\\hat w_k-\\hat u_k)^2\\gamma_k\\right)^{\\frac12}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " A distinct feature of the discrete projection approach is that one can compute only the coefficients that are important for a given problem without evaluating the rest of the expansion coefficients. This may happen, for example, when global sensitivity is required for some input random variables $\\xi$. This is in contrast to the gPC Galerkin method, where all the gPC coefficients are coupled and solved simultaneously."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 130,
   "position": {
    "height": "152px",
    "left": "889px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
